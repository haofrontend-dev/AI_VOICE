# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/OpenBMB/VoxCPM.git
# %cd VoxCPM
!pip install -q voxcpm torchcodec==0.9

"""# Test on CLI"""

from huggingface_hub import snapshot_download
snapshot_download("JayLL13/VoxCPM-1.5-VN", local_dir="./pretrained/VoxCPM-1.5-VN")


# =========================
# VoxCPM - Dark UI (VN) - Click-to-Generate
# =========================
import os
import gradio as gr
import soundfile as sf
import torch
from voxcpm import VoxCPM

# ---- Torch perf knobs ----
os.environ["TORCHDYNAMO_DISABLE"] = "1"
try:
    torch._dynamo.disable()
except Exception:
    pass

try:
    import torch._inductor.config as config
    config.triton.cudagraphs = False
except Exception:
    pass

torch.backends.cuda.matmul.allow_tf32 = True

# Set default dtype to float32 to prevent bfloat16 issues on CPU
torch.set_default_dtype(torch.float32)

# ---- Paths ----
INPUT_AUDIO_PATH = "input.wav"
OUTPUT_AUDIO_PATH = "output.wav"

sample_prompt_text = (
    "L√†m content m√† ng·∫°i thu √¢m th√¨ ph·∫£i l√†m sao? "
    "H√¥m nay m√¨nh demo cho anh em c√°ch m√¨nh d√πng."
)

# ---- Load model once ----
print("Loading VoxCPM model...")
model = VoxCPM.from_pretrained("JayLL13/VoxCPM-1.5-VN")
# The explicit .to(torch.float32) call here is technically redundant if dtype is passed correctly, but harmless
# model.to(torch.float32) # Removed this line as it causes an AttributeError
print("Model loaded!")

def _clamp(v, lo, hi):
    return max(lo, min(hi, v))

def luu_ghi_am(audio_np):
    """audio_np: (sr, np.ndarray) with gr.Audio(type='numpy')"""
    if audio_np is None:
        return (
            gr.update(value="‚ùå Ch∆∞a c√≥ √¢m thanh. H√£y ghi √¢m ho·∫∑c upload file."),
            gr.update(value=False),
        )

    sr, data = audio_np
    sf.write(INPUT_AUDIO_PATH, data, sr)
    return (
        gr.update(value=f"‚úÖ ƒê√£ l∆∞u: {INPUT_AUDIO_PATH} (sr={sr})"),
        gr.update(value=True),
    )

@torch.inference_mode()
def tao_giong_noi(
    van_ban_muc_tieu: str,
    van_ban_mau: str,
    cfg_value: float,
    so_buoc: int,
    chuan_hoa: bool,
    khu_nhieu: bool,
    tu_thu_lai: bool,
):
    van_ban_muc_tieu = (van_ban_muc_tieu or "").strip()
    van_ban_mau = (van_ban_mau or "").strip()

    if van_ban_muc_tieu == "":
        return None, "‚è≥ **Nh·∫≠p vƒÉn b·∫£n m·ª•c ti√™u** ƒë·ªÉ b·∫Øt ƒë·∫ßu."

    if not os.path.exists(INPUT_AUDIO_PATH):
        return None, "üé§ **Ch∆∞a c√≥ gi·ªçng m·∫´u**. H√£y ghi √¢m v√† b·∫•m **L∆∞u ghi √¢m** tr∆∞·ªõc."

    # Clamp ƒë·ªÉ kh√¥ng crash n·∫øu user g√µ tr·ª±c ti·∫øp ngo√†i range
    so_buoc = _clamp(int(so_buoc), 4, 30)
    cfg_value = _clamp(float(cfg_value), 1.0, 3.0)

    # VoxCPM requirement: c√≥ prompt_wav th√¨ prompt_text kh√¥ng ƒë∆∞·ª£c None/r·ªóng
    if van_ban_mau == "":
        return None, "‚ùå C√≥ **gi·ªçng m·∫´u** th√¨ **VƒÉn b·∫£n gi·ªçng m·∫´u** kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng (ph·∫£i kh·ªõp n·ªôi dung b·∫°n ƒë·ªçc)."

    status = f"üöÄ ƒêang t·∫°o gi·ªçng... (CFG={cfg_value:.1f}, Steps={so_buoc})"

    wav = model.generate(
        text=van_ban_muc_tieu,
        prompt_wav_path=INPUT_AUDIO_PATH,
        prompt_text=van_ban_mau,
        cfg_value=cfg_value,
        inference_timesteps=so_buoc,
        normalize=bool(chuan_hoa),
        denoise=bool(khu_nhieu),
        retry_badcase=bool(tu_thu_lai),
        retry_badcase_max_times=3,
        retry_badcase_ratio_threshold=6.0,
    )

    sf.write(OUTPUT_AUDIO_PATH, wav, model.tts_model.sample_rate)
    return OUTPUT_AUDIO_PATH, f"‚úÖ **Xong!** ¬∑ CFG={cfg_value:.1f} ¬∑ Steps={so_buoc}"

# =========================
# UI Theme + CSS (Dark, Card)
# =========================
dark_css = """
:root { color-scheme: dark; }

.gradio-container {
  background: radial-gradient(1200px 600px at 20% 0%, rgba(59,130,246,0.22), transparent 55%),
              radial-gradient(900px 500px at 80% 10%, rgba(99,102,241,0.18), transparent 55%),
              #070b14 !important;
}

#app_title h1 { font-size: 1.35rem !important; margin-bottom: 0.2rem !important; }
#sub_title { opacity: 0.9; margin-bottom: 0.8rem; }

.card {
  background: rgba(17, 24, 39, 0.86) !important;
  border: 1px solid rgba(255,255,255,0.08) !important;
  border-radius: 18px !important;
  padding: 14px !important;
}

textarea, input[type="text"] {
  background: rgba(2, 6, 23, 0.85) !important;
  color: #e5e7eb !important;
  border: 1px solid rgba(255,255,255,0.10) !important;
  border-radius: 14px !important;
}

button { border-radius: 14px !important; }

.hr { height: 1px; background: rgba(255,255,255,0.08); margin: 10px 0 12px 0; }
.small_note { font-size: 0.88rem; opacity: 0.9; }
"""

theme = gr.themes.Soft(
    primary_hue="blue",
    secondary_hue="gray",
    neutral_hue="slate",
    font=[gr.themes.GoogleFont("Inter"), "Arial", "sans-serif"],
).set(
    body_background_fill="#070b14",
    block_background_fill="rgba(17, 24, 39, 0.86)",
)

# =========================
# Build UI (CLICK ONLY)
# =========================
with gr.Blocks(theme=theme, css=dark_css, title="VoxCPM Voice Cloning (VN)") as demo:
    gr.Markdown("# üé§ VoxCPM Voice Cloning (VN ‚Ä¢ Dark)", elem_id="app_title")
    gr.Markdown(
        "B·∫•m **L∆∞u ghi √¢m** ƒë·ªÉ l∆∞u gi·ªçng m·∫´u, sau ƒë√≥ b·∫•m **T·∫°o gi·ªçng** ƒë·ªÉ generate. "
        "G·ª£i √Ω: **CFG 1.8‚Äì2.2**, **Steps 18‚Äì22**.",
        elem_id="sub_title",
    )

    with gr.Row():
        with gr.Column(scale=1, elem_classes=["card"]):
            gr.Markdown("## 1) Gi·ªçng m·∫´u (b·∫Øt bu·ªôc)")
            gr.Markdown("üí° *Ghi √¢m 10‚Äì25s, n√≥i t·ª± nhi√™n, tr√°nh nh·∫°c n·ªÅn/echo.*", elem_classes=["small_note"])

            audio_in = gr.Audio(
                sources=["microphone", "upload"],
                type="numpy",
                label="√Çm thanh gi·ªçng m·∫´u (Mic / T·∫£i l√™n)",
            )
            btn_save = gr.Button("üé§ L∆∞u ghi √¢m", variant="primary")
            save_status = gr.Textbox(label="Tr·∫°ng th√°i", interactive=False)
            has_audio_flag = gr.Checkbox(label="ƒê√£ c√≥ gi·ªçng m·∫´u", value=False, interactive=False)

            gr.HTML('<div class="hr"></div>')

            gr.Markdown("## 2) VƒÉn b·∫£n gi·ªçng m·∫´u")
            prompt_text = gr.Textbox(
                value=sample_prompt_text,
                lines=4,
                label="VƒÉn b·∫£n ƒë√∫ng nh∆∞ b·∫°n ƒë√£ ƒë·ªçc (kh·ªõp 100%)",
            )

        with gr.Column(scale=1, elem_classes=["card"]):
            gr.Markdown("## 3) VƒÉn b·∫£n m·ª•c ti√™u")
            target_text = gr.Textbox(
                value="Xin ch√†o c√°c b·∫°n. T√¥i t√™n l√† Anh ƒê·ª©c. T√¥i r·∫•t l√† x·∫•u trai. C√°c b·∫°n n√≥i l√† ƒë√∫ng ƒëi",
                lines=4,
                label="VƒÉn b·∫£n mu·ªën chuy·ªÉn sang gi·ªçng ƒë√£ clone",
            )

            with gr.Tabs():
                with gr.Tab("C∆° b·∫£n"):
                    with gr.Row():
                        cfg = gr.Slider(
                            1.0, 3.0, value=2.0, step=0.1,
                            label="CFG (m·ª©c b√°m gi·ªçng)",
                            info="TƒÉng ƒë·ªÉ gi·ªëng gi·ªçng m·∫´u h∆°n; gi·∫£m ƒë·ªÉ t·ª± nhi√™n h∆°n"
                        )
                        steps = gr.Slider(
                            4, 30, value=20, step=1,
                            label="S·ªë b∆∞·ªõc suy lu·∫≠n",
                            info="Nhi·ªÅu h∆°n th∆∞·ªùng m∆∞·ª£t h∆°n nh∆∞ng ch·∫≠m h∆°n"
                        )
                with gr.Tab("N√¢ng cao"):
                    with gr.Row():
                        chuan_hoa = gr.Checkbox(value=False, label="Chu·∫©n ho√° vƒÉn b·∫£n")
                        khu_nhieu = gr.Checkbox(value=False, label="Kh·ª≠ nhi·ªÖu gi·ªçng m·∫´u")
                        tu_thu_lai = gr.Checkbox(value=True, label="T·ª± th·ª≠ l·∫°i khi l·ªói")

            btn_generate = gr.Button("‚ö° T·∫°o gi·ªçng", variant="primary")
            out_audio = gr.Audio(label="√Çm thanh ƒë·∫ßu ra", type="filepath")
            status_md = gr.Markdown("‚è≥ Ch∆∞a ch·∫°y.")

    # Wiring: ONLY CLICK
    btn_save.click(fn=luu_ghi_am, inputs=audio_in, outputs=[save_status, has_audio_flag])

    btn_generate.click(
        fn=tao_giong_noi,
        inputs=[target_text, prompt_text, cfg, steps, chuan_hoa, khu_nhieu, tu_thu_lai],
        outputs=[out_audio, status_md],
        show_progress=True,
    )

demo.queue(max_size=10, default_concurrency_limit=1).launch(debug=True)